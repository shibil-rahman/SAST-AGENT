{
    "cells": [
        {
            "metadata": {},
            "cell_type": "code",
            "source": "import pandas as pd\nimport joblib\nfrom datetime import datetime\nimport csv\nimport os\nimport json\nimport re\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import RobustScaler",
            "execution_count": 2,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git config --global user.email \"shibilr6@gmail.com\"\n!git config --global user.name \"shibil-rahman\"",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git init\n!git add .\n!git commit -m \"Initial commit\"",
            "execution_count": 7,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Reinitialized existing Git repository in /home/wsuser/work/.git/\nOn branch master\n\nInitial commit\n\nnothing to commit (create/copy files and use \"git add\" to track)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git remote add origin https://github.com/shibil-rahman/SAST-AGENT.git",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git checkout -b master",
            "execution_count": 13,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Switched to a new branch 'master'\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git pull origin master",
            "execution_count": 26,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "remote: Enumerating objects: 7, done.\u001b[K\nremote: Counting objects: 100% (7/7), done.\u001b[K\nremote: Compressing objects: 100% (5/5), done.\u001b[K\nremote: Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\nUnpacking objects: 100% (5/5), 1.48 KiB | 378.00 KiB/s, done.\nFrom https://github.com/shibil-rahman/SAST-AGENT\n * branch            master     -> FETCH_HEAD\n   a8f783a..658b832  master     -> origin/master\nUpdating a8f783a..658b832\nFast-forward\n encoder.pkl | Bin \u001b[31m804\u001b[m -> \u001b[32m929\u001b[m bytes\n 1 file changed, 0 insertions(+), 0 deletions(-)\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "def keep_rows_between(input_file, output_file, start_value, end_value):\n    with open(input_file, 'r', newline='') as infile, open(output_file, 'w', newline='') as outfile:\n        reader = csv.reader(infile)\n        writer = csv.writer(outfile)\n        \n        rows_to_keep = []\n        keep_mode = False\n        \n        for row in reader:\n            if start_value in row:\n                keep_mode = True\n            if keep_mode and (start_value not in row and end_value not in row):\n                rows_to_keep.append(row)\n            if end_value in row:\n                keep_mode = False\n        \n        writer.writerows(rows_to_keep)\n        \ninput_file_path = 'data/Report_Static_jazzcalm_workspace_2023-02-17_04-22-33_2023-03-02-2.csv'\noutput_file_path = 'data/sast_report.csv'\n\nstart_value = 'Issue Attributes:'\nend_value = 'Fix Group Attributes:'\nkeep_rows_between(input_file_path, output_file_path, start_value, end_value)",
            "execution_count": 13,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "df = pd.read_csv('data/sast_report.csv')\ndf = df.dropna(subset=['Severity Id']).astype({'Severity Id': int})\ncoloumnlist = [\"Severity Id\",\"Issue Type Name\" ,\"Threat Class\", \"Security Risk\", \"Cause\"]\ndf = df[coloumnlist].drop_duplicates().fillna('').reset_index(drop=True)\n\n# Load the new dataset and preprocess it\nnew_data = df\nX_new_text = new_data.drop(columns=['Severity Id'])\nX_new_numerical = new_data[['Severity Id']]\n\n# Load the previously fitted encoder and transform the numerical features of the new data\nencoder = joblib.load(\"src/encoder.pkl\")\nX_new_numerical_encoded = encoder.transform(X_new_numerical)\n\n# Load the previously fitted TF-IDF vectorizer and transform the text features of the new data\ntfidf_vectorizer = joblib.load(\"src/tfidf_vectorizer.pkl\")\nX_new_text_tfidf = tfidf_vectorizer.transform(X_new_text['Issue Type Name'] + ' ' + X_new_text['Cause'] + ' ' + X_new_text['Threat Class'] + ' ' + X_new_text['Security Risk'])\n\n# Concatenate text and numerical features for the new data\nX_new_combined = pd.concat([pd.DataFrame(X_new_numerical_encoded.toarray()), pd.DataFrame(X_new_text_tfidf.toarray())], axis=1)\n\n# Load the previously trained classifier\nmultioutput_classifier_tuned = joblib.load(\"src/multioutput_classifier_tuned.pkl\")\n\n# Use the already trained classifier to predict the outputs for the new data\ny_new_pred = multioutput_classifier_tuned.predict(X_new_combined)\n\n# Get the predictions for Analysis Result and Result columns\ny_new_analysis_result_pred = y_new_pred[:, 0]\ny_new_result_pred = y_new_pred[:, 1]\n\n# Add the predictions to the new_data DataFrame\nnew_data['Analysis Result Prediction'] = y_new_analysis_result_pred\nnew_data['Result Prediction'] = y_new_result_pred\n\n# Save the DataFrame with the new 'Result' column to a new CSV file\ncurrent_datetime = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\noutput_file_path = f'output_data_{current_datetime}.csv'\nnew_data.to_csv(output_file_path, index=False)\n\nprint(f\"Predictions saved to '{output_file_path}'.\")",
            "execution_count": 19,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator OneHotEncoder from version 1.2.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.2.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 1.2.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n/opt/conda/envs/Python-3.10/lib/python3.10/site-packages/sklearn/base.py:329: UserWarning: Trying to unpickle estimator MultiOutputClassifier from version 1.2.2 when using version 1.1.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\nhttps://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n  warnings.warn(\n",
                    "name": "stderr"
                },
                {
                    "output_type": "stream",
                    "text": "Predictions saved to 'output_data_20230810_151835.csv'.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ls -al",
            "execution_count": 20,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "total 72\r\ndrwxrwx--- 5 wsuser wscommon  4096 Aug 10 15:18  \u001b[0m\u001b[01;34m.\u001b[0m/\r\ndrwxrwx--- 1 wsuser wscommon  4096 Aug 10 14:46  \u001b[01;34m..\u001b[0m/\r\ndrwxrwx--- 2 wsuser wscommon  4096 Aug 10 15:17  \u001b[01;34mdata\u001b[0m/\r\ndrwxrwx--- 8 wsuser wscommon  4096 Aug 10 15:12  \u001b[01;34m.git\u001b[0m/\r\n-rw-rw---- 1 wsuser wscommon 26796 Aug 10 14:50 'Multi class Multi output classifier Model.ipynb'\r\n-rw-rw---- 1 wsuser wscommon  5331 Aug 10 15:11  output_data_20230810_151115.csv\r\n-rw-rw---- 1 wsuser wscommon  5331 Aug 10 15:18  output_data_20230810_151835.csv\r\n-rw-rw---- 1 wsuser wscommon    12 Aug 10 14:50  README.md\r\ndrwxrwx--- 2 wsuser wscommon  4096 Aug 10 15:14  \u001b[01;34msrc\u001b[0m/\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "print(joblib.__version__)",
            "execution_count": 29,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "1.1.1\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "pip install joblib==1.2.0",
            "execution_count": 30,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Collecting joblib==1.2.0\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: joblib\n  Attempting uninstall: joblib\n    Found existing installation: joblib 1.1.1\n    Uninstalling joblib-1.1.1:\n      Successfully uninstalled joblib-1.1.1\nSuccessfully installed joblib-1.2.0\nNote: you may need to restart the kernel to use updated packages.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "!git add .\n!git commit -m \"resource grouping\"\n!git push -u https://shibil-rahman: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@github.com/shibil-rahman/SAST-AGENT.git master",
            "execution_count": 21,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "[master 576ce76] resource grouping\n 6 files changed, 22 insertions(+)\n rename Report_Static_jazzcalm_workspace_2023-02-17_04-22-33_2023-03-02-2.csv => data/Report_Static_jazzcalm_workspace_2023-02-17_04-22-33_2023-03-02-2.csv (100%)\n rename sast_report.csv => data/sast_report.csv (100%)\n create mode 100644 output_data_20230810_151835.csv\n rename encoder.pkl => src/encoder.pkl (100%)\n rename multioutput_classifier_tuned.pkl => src/multioutput_classifier_tuned.pkl (100%)\n rename tfidf_vectorizer.pkl => src/tfidf_vectorizer.pkl (100%)\nEnumerating objects: 5, done.\nCounting objects: 100% (5/5), done.\nDelta compression using up to 56 threads\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 616 bytes | 616.00 KiB/s, done.\nTotal 4 (delta 1), reused 0 (delta 0), pack-reused 0\nremote: Resolving deltas: 100% (1/1), completed with 1 local object.\u001b[K\nTo https://github.com/shibil-rahman/SAST-AGENT.git\n   66e8e9f..576ce76  master -> master\nbranch 'master' set up to track 'https://shibil-rahman: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@github.com/shibil-rahman/SAST-AGENT.git/master'.\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mkdir src",
            "execution_count": 6,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mv multioutput_classifier_tuned.pkl src/multioutput_classifier_tuned.pkl",
            "execution_count": 8,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mv encoder.pkl src/encoder.pkl",
            "execution_count": 9,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mv tfidf_vectorizer.pkl src/tfidf_vectorizer.pkl",
            "execution_count": 10,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mkdir data",
            "execution_count": 11,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "mv Report_Static_jazzcalm_workspace_2023-02-17_04-22-33_2023-03-02-2.csv data/Report_Static_jazzcalm_workspace_2023-02-17_04-22-33_2023-03-02-2.csv",
            "execution_count": 12,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "cd data",
            "execution_count": 14,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/home/wsuser/work/data\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "ls",
            "execution_count": 15,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Report_Static_jazzcalm_workspace_2023-02-17_04-22-33_2023-03-02-2.csv\r\nsast_report.csv\r\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "cd -",
            "execution_count": 17,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "/home/wsuser/work\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "rm sast_report.csv",
            "execution_count": 18,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": 22,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "code",
            "source": "",
            "execution_count": null,
            "outputs": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.10",
            "language": "python"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.9",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}